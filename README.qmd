---
format: gfm
---
```{python}
#| echo: false
#| output: false

from srn_docs_api import get_srn_companies, get_srn_documents
import pandas as pd
import numpy as np

SRN_API_URL = "https://api.sustainabilityreportingnavigator.com/api/"

def prep_table():
    companies = pd.DataFrame(get_srn_companies())
    documents = pd.DataFrame(get_srn_documents())
    df = documents.merge(companies, left_on='company_id', right_on='id')
    df = df[['country', 'type', 'year', 'company_id']]
    df['type'] = df['type'].str.strip()

    # table 1
    table_1 = df.groupby(['country', 'year']).agg(
        {'company_id': 'nunique'}).reset_index()

    # Pivot the table to have separate columns for the number of AR and SR
    table_1 = (table_1
               .pivot(index='country', columns='year', values='company_id')
               .reset_index()
               .replace(np.nan, None)
               .rename(columns={"country": "Country"}))

    table_1 = table_1.to_markdown(index=False, intfmt=",", missingval='')

    # table 2
    table_2 = (pd.concat([df, pd.get_dummies(df['type'])], axis=1).
               rename(columns={"country": "Country"}))
    aggregations = {}
    for col in table_2.columns[3:]:
        aggregations[col] = 'nunique' if col == 'company_id' else 'sum'

    ocols = ['# Firms', 'AR', 'SR', 'IR', 'CDP']
    ncols = [c for c in table_2.columns[4:] if c not in ocols and c != "Other"]
    ocols = ocols + ncols + ['Other']

    table_2 = (table_2
               .drop('year', axis=1)
               .groupby('Country')
               .agg(aggregations)
               .replace(np.nan, None)
               .rename(columns={"company_id": "# Firms"}))
    table_2 = table_2[ocols].to_markdown(intfmt=",")

    return df, table_1, table_2
df, table_1, table_2 = prep_table()
```
## Sustainability Reporting Navigator Document Database

This repository features the document data and API of the 
[Sustainabity Reporting Navigator](https://www.sustainabilityreportingnavigator.com).
The large bulk of the initial reports in our database comes from the generous contribution by Arianna Pisciella, Gaia Melloni, Bianca Minuth, and Paul Pronobis and is supplemented by the ongoing data collection of the SRN team. Our objective is to develop this repository into a collaborative data platform that 
provides extensive coverage of sustainability-related documents published 
by European publicly-listed firms.


### Coverage

```{python}
#| echo: false
#| output: asis
print(
f'''
Currently our data covers {len(df):,} documents from {len(df.company_id.unique()):,} firms spanning {len(df.country.unique())} countries and data from the time period {df.year.min()} to {df.year.max()}. Further information on the covered firm-years can be assessed from the table below.
'''
)
```

```{python}
#| echo: false
#| output: asis

print(table_1)
```

### Included report types

We try to collect all documents that contain relevant sustainability 
information. This includes but is not limited to annual and sustainability
reports (AR and SR). For some firms it also includes additional reports like
integreated reports (IR), Carbon Diclosure Project data (CDP) and other 
reporting formats. All materials are referred to by URL links and are 
provided as is. Neither the team of the SRN nor the maintainers 
of this data repository claim any ownership of or legal rights to the 
provided data. 

```{python}
#| echo: false
#| output: asis

print(table_2)
```


### How can I download the data?

We provide an easy to use API for data download. See the file `srn_docs_api.py` 
in this repo for pointers. We are working on making this process even easier 
to handle over the next weeks. Stay tuned!

### How do I cite the data?

Thank you for asking! We very much appreciate you giving credit to our data 
collection efforts. We will be using a concept DOI and versioned DOIs 
from Zenodo in the future. Currently, please cite the data as follows:

Donau, Charlotte-Louise, Fikir Worku Edossa, Joachim Gassen, Gaia Melloni, Inga Meringdal, Bianca Minuth, Arianna Piscella, Paul Pronobis and Victor Wagner (2023): SRN Document Database, https://github.com/trr266/srn_docs.

### How can I post-process the data?

What a great question! We really hope that this repo will be used to discuss 
data quality issues as well as methods to use the data in research
projects. Again, as a first teaser, take a look at 
`extraxt_text_from_docs.py` that features a method to extract page-wise 
text data from our documents.


### I think I found something odd in the data. Whom should I contact?

Thank you! Please open an issue on GitHub, mentioning the document id 
and describing the issue that you encountered.


### This is great! Can I help?

Thank you and yes, of course! We would be very happy about people that 
provide historical data and/or are willing to maintain our data going 
forward on a country or index basis. So, if you would like to help, please
reach out to [Victor Wagner](victor.wagner@lmu.de).

